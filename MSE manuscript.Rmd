---
title: 'No Replication Without Process Documentation:  An Assessment of Management
  Strategy '
author:
- affiliation: School for Marine Science and Technology, University of Massachusetts - Dartmouth
  name: Jonathan W. Cummings
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    keep_tex: yes
    latex_engine: pdflatex
    template: svm-latex-ms.tex
biblio-style: apsr
endnote: no
fontfamily: mathpazo
fontsize: 11pt
geometry: margin=1in
header-includes: \usepackage{hyperref}
keywords: pandoc, r markdown, knitr
bibliography: MSEreview.bib
abstract: Enter abstract text here
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE,
                      message=FALSE, warning=FALSE,
                      fig.path='figs/',
                      cache.path = '_cache/',
                      fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      })
```

```{r load data, include=FALSE}
options(knitr.table.format = "html")
##### load libraries #####
library(tidyverse) # upgrade to base R
library(readxl) # read in excel files
library(shiny) # Shiny App
library(shinythemes) # web themes for Shiny
library(DT) # Data Table
library(purrr) # for loop alternative
library(ggmap) # map plotting
library(mapdata) # basemap generation
library(odbc) # database connection 
library(RMySQL) # MySQL scripting in R
library(DBI) # database interface
library(kableExtra) # extra formating of the tables

load("C:/Users/jcummings/OneDrive - UMASS Dartmouth/SMAST/Research/MSE Problem Framing/MSEreview/MSEreview.RData")

study<-study %>% 
  unite(Citation,c(Authors,YearPub),sep=" ",remove=F)

mgmt.join<-mgmt %>% 
  group_by(fkStudyID) %>%
  summarise(ManagementType = toString(sort(unique(ManagementType))),
            AlternativesEvaluated = toString(sort(unique(AlternativesEvaluated))))

obj.join<-obj %>%
  group_by(fkStudyID) %>%
  summarise(ObjectiveCategories = toString(sort(unique(ObjCategory))))

# Join tables
data<-full_join(study,mgmt.join,by=c("ID"="fkStudyID"))
data<-full_join(data,obj.join,by=c("ID"="fkStudyID"))

# Move comment column to the end
data<-data %>%
  select(-'Comments', 'Comments')
```

```{r filter data, include=FALSE}

# Filter data by study type
data_pub<-filter(data,IncludeInPublication==TRUE)
data_CC<-filter(data,str_detect(Drivers,"Climate Change"))

data_pub.join<-data_pub %>%
  select(ID,Citation)
data_CC.join<-data_CC %>%
  select(ID,Citation)

obj.data_pub<-left_join(data_pub.join,obj,by=c("ID"="fkStudyID"))%>%
  select(-c("ID","ID.y"))
obj.data_CC<-left_join(data_CC.join,obj,by=c("ID"="fkStudyID"))%>%
  select(-c("ID","ID.y"))

alt.data_pub<-left_join(data_pub.join,mgmt,by=c("ID"="fkStudyID"))%>%
  select(-c("ID","ID.y"))
alt.data_CC<-left_join(data_CC.join,mgmt,by=c("ID"="fkStudyID"))%>%
  select(-c("ID","ID.y"))

data_pub<-data_pub %>%
  select(-c("ID"))
data_CC<-data_CC %>%
  select(-c("ID"))

# Get columns whose width needs editing
targets<-match(c("FullCitation","Comments"),names(data))

#####-- Filter Data by analysis --#####
# Get columns for study summary
summary.col<-c("Citation",
               "Species",
               "Location",
               "System")
# Get columns for study drivers and problem
prob.col<-c("Citation",
            "ProblemDefinition",
            "Drivers",
            "ConsequencePrediction",
            "TradeOffMethod_Exp",
            "TradeOffMethod_Sub",
            "Decision")
# Get columns for frequency analysis
freq.col<-c("ProcessExplicit",
            "ProblemDefinitionExplicit",
            "ObjectivesExplicit",
            "AlternativesExplicit",
            "TradeOffsExplicit",
            "DecisionExplicit")
freq2.col<-c("RolesExplicit",
            "OpenMeetings",
            "ResultsAdopted")
# Get columns for participant analysis
part.col<-c("Leader",
            "Participants",
            "ObjElicitationSource_Exp",
            "ProcedureElicitation_Exp",
            "ObjElicitationSource_Sub",
            "ProcedureElicitation_Sub")
obj.col<-c("ObjType",
           "ObjCategory",
           "ObjDirection",
           "ObjScale")
alt.col<-c("ManagementType",
           "AlternativesEvaluated")
# Get columns for map
map.col<-c("Latitude",
           "Longitude",
           "Citation",
           "Drivers")

# Select data summary columns
summary.data_pub<-data_pub %>%
    select(summary.col)
summary.data_CC<-data_CC %>%
  select(summary.col)
```

```{r analyze data, include=FALSE}
options(knitr.table.format = "html")
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      tidy = FALSE,
                      message = FALSE,
                      fig.align = 'center',
                      out.width = "100%")

# Frequency of method
n_mse<-nrow(data)
n_pub<-nrow(data_pub)
n_obj_pub<-nrow(obj.data_pub)
n_CC<-nrow(data_CC)
n_obj_CC<-nrow(obj.data_CC)

freq.data_pub<-data_pub %>%
    select(freq.col) %>%
    rename("Process"="ProcessExplicit",
           "Problem"="ProblemDefinitionExplicit",
           "Objectives"="ObjectivesExplicit",
           "Alternatives"="AlternativesExplicit",
           "Tradeoffs"="TradeOffsExplicit",
           "Decision"="DecisionExplicit") %>%
    summarise_all(funs(sum))%>%
    gather(Explicit) %>%
    mutate(Percent=value/n_mse*100) %>%
    mutate(Explicit=factor(Explicit,levels=
                  c("Process","Problem","Objectives","Alternatives","Tradeoffs","Decision"))) %>%
    rename("Number"="value")

freq.data_CC<-data_CC %>%
  select(freq.col) %>%
  rename("Process"="ProcessExplicit",
         "Problem"="ProblemDefinitionExplicit",
         "Objectives"="ObjectivesExplicit",
         "Alternatives"="AlternativesExplicit",
         "Tradeoffs"="TradeOffsExplicit",
         "Decision"="DecisionExplicit") %>%
  summarise_all(funs(sum))%>%
  gather(Explicit) %>%
  mutate(Percent=value/n_mse*100) %>%
  mutate(Explicit=factor(Explicit,levels=
                           c("Process","Problem","Objectives","Alternatives","Tradeoffs","Decision"))) %>%
  rename("Number"="value")

# Who participates
part.data_pub<-data_pub %>%
    select(part.col) %>%
    rename("Process"="Leader",
           "Doc Objectives"="ObjElicitationSource_Exp",
           "Doc Alternatives"="ProcedureElicitation_Exp",
           "Sub Objectives"="ObjElicitationSource_Sub",
           "Sub Alternatives"="ProcedureElicitation_Sub")

part.data_pub<- part.data_pub %>%
    purrr::map(~ strsplit(as.character(.),split=",")) %>%
    purrr::map(unlist) %>%
    purrr::map(table)


part.data_pub<-plyr::ldply(part.data_pub,data.frame)
colnames(part.data_pub)<-c("Stage","Participants","Number")

neworder <- c("Process","Participants","Doc Objectives",
              "Sub Objectives","Doc Alternatives",
              "Sub Alternatives")
newlabels <- c("Process","Participants","Explicit Objectives Process",
               "Subjective Objectives Process","Explicit Alternatives Process",
               "Subjective Alternatives Process")

part.data_pub <- part.data_pub %>%
    mutate(Percent=Number/n_pub*100) %>%
    mutate(Stage=factor(Stage,levels=neworder,labels=newlabels)) %>%
    ungroup() %>%
    # 2. Arrange by
    #   i.  facet group =Stage
    #   ii. bar height
    arrange(Stage, Percent) %>%
    # 3. Add order column of row numbers
    mutate(order = row_number())

part.data_CC<-data_CC %>%
  select(part.col) %>%
  rename("Process"="Leader",
         "Doc Objectives"="ObjElicitationSource_Exp",
         "Doc Alternatives"="ProcedureElicitation_Exp",
         "Sub Objectives"="ObjElicitationSource_Sub",
         "Sub Alternatives"="ProcedureElicitation_Sub")

part.data_CC<- part.data_CC %>%
  purrr::map(~ strsplit(as.character(.),split=",")) %>%
  purrr::map(unlist) %>%
  purrr::map(table)


part.data_CC<-plyr::ldply(part.data_CC,data.frame)
colnames(part.data_CC)<-c("Stage","Participants","Number")

part.data_CC <- part.data_CC %>%
  mutate(Percent=Number/n_CC*100) %>%
  mutate(Stage=factor(Stage,levels=neworder,labels=newlabels)) %>%
  ungroup() %>%
  # 2. Arrange by
  #   i.  facet group =Stage
  #   ii. bar height
  arrange(Stage, Percent) %>%
  # 3. Add order column of row numbers
  mutate(order = row_number())

part.dataTable_pub<-part.data_pub %>%
    as_tibble() %>%
    select(Stage,Participants,Number) %>%
    rename("Participant Group"="Participants") %>%
    spread(Stage,Number,fill=0)

part.dataTable_CC<-part.data_CC %>%
  as_tibble() %>%
  select(Stage,Participants,Number) %>%
  rename("Participant Group"="Participants") %>%
  spread(Stage,Number,fill=0)

# What drivers are considered
drive.data_pub<-data_pub %>%
    select(Drivers) %>%
    purrr::map(~ strsplit(as.character(.),split=",")) %>%
    purrr::map(unlist) %>%
    purrr::map(table) %>%
    plyr::ldply(data.frame) %>%
    select(Var1,Freq) %>%
    rename("Driver"="Var1","Frequency"="Freq") %>%
    mutate(Percent=Frequency/n_pub*100) %>%
    arrange(desc(Frequency))

drive.data_CC<-data_CC %>%
  select(Drivers) %>%
  purrr::map(~ strsplit(as.character(.),split=",")) %>%
  purrr::map(unlist) %>%
  purrr::map(table) %>%
  plyr::ldply(data.frame) %>%
  select(Var1,Freq) %>%
  rename("Driver"="Var1","Frequency"="Freq") %>%
  mutate(Percent=Frequency/n_CC*100) %>%
  arrange(desc(Frequency))

# What objectives categories were considered
objcat.data_pub<-data_pub %>%
    select(ObjectiveCategories) %>%
    purrr::map(~ strsplit(as.character(.),split=", ")) %>%
    purrr::map(unlist) %>%
    purrr::map(table) %>%
    plyr::ldply(data.frame) %>%
    select(Var1,Freq) %>%
    rename("Objective Category"="Var1","Frequency"="Freq") %>%
    mutate(Percent=Frequency/n_pub*100) %>%
    arrange(desc(Frequency))

objcat.data_CC<-data_CC %>%
  select(ObjectiveCategories) %>%
  purrr::map(~ strsplit(as.character(.),split=", ")) %>%
  purrr::map(unlist) %>%
  purrr::map(table) %>%
  plyr::ldply(data.frame) %>%
  select(Var1,Freq) %>%
  rename("Objective Category"="Var1","Frequency"="Freq") %>%
  mutate(Percent=Frequency/n_CC*100) %>%
  arrange(desc(Frequency))

# How were objectives defined
obj.data_pub<-obj.data_pub %>%
  select(obj.col) %>%
  purrr::map(table) %>%
  plyr::ldply(data.frame)

obj.data_CC<-obj.data_CC %>%
  select(obj.col) %>%
  purrr::map(table) %>%
  plyr::ldply(data.frame)

colnames(obj.data_pub)<-colnames(obj.data_CC)<-c("Objective","Type","Number")

neworder <- c("ObjCategory","ObjType","ObjDirection","ObjScale")
newlabels <- c("Category","Type","Direction","Scale")

# What Objective types are considered
obj.dataTable_pub <- obj.data_pub %>%
  mutate(Percent=round(Number/n_obj_pub*100,0)) %>%
  mutate('Per MSE'=round(Number/n_pub,2)) %>%
  mutate(Objective=factor(Objective,levels=neworder,labels=newlabels)) %>%
  arrange(Objective,desc(Number))

obj.dataTable_CC <- obj.data_CC %>%
  mutate(Percent=round(Number/n_obj_CC*100,0)) %>%
  mutate('Per MSE'=round(Number/n_CC,2)) %>%
  mutate(Objective=factor(Objective,levels=neworder,labels=newlabels)) %>%
  arrange(Objective,desc(Number))

# What Alternative types are considered
altcat.data_pub<-alt.data_pub %>%
    select(ManagementType) %>%
    purrr::map(~ strsplit(as.character(.),split=",")) %>%
    purrr::map(unlist) %>%
    purrr::map(table) %>%
    plyr::ldply(data.frame) %>%
    select(Var1,Freq) %>%
    rename("Management Type"="Var1","Number"="Freq") %>%
    mutate(Percent=round(Number/n_pub*100,0)) %>%
    mutate('Per MSE'=round(Number/n_pub,2)) %>%
    arrange(desc(Number))

altcat.data_CC<-alt.data_CC %>%
  select(ManagementType) %>%
  purrr::map(~ strsplit(as.character(.),split=", ")) %>%
  purrr::map(unlist) %>%
  purrr::map(table) %>%
  plyr::ldply(data.frame) %>%
  select(Var1,Freq) %>%
  rename("Management Type"="Var1","Number"="Freq") %>%
  mutate(Percent=round(Number/n_CC*100,0)) %>%
  mutate('Per MSE'=round(Number/n_CC,2)) %>%
  arrange(desc(Number))

# Get map background for plotting the map
world <- borders("world", colour="gray50", fill="gray50", alpha=0.75) # create a layer of borders

# Where MSEs have occured
map.data<-rbind(data_pub,data_CC) %>%
  select(map.col) %>%
  mutate(Drivers=str_extract(Drivers, "Climate Change")) %>%
  mutate(Drivers=replace_na(Drivers, "Random Sample"))

# label MSEs articles by analysis for ploting
freq.data_pub<-mutate(freq.data_pub,Analysis="Random Sample")
freq.data_CC<-mutate(freq.data_CC,Analysis="Climate Change")
freq.data<-rbind(freq.data_pub,freq.data_CC)
part.data_pub<-mutate(part.data_pub,Analysis="Random Sample")
part.data_CC<-mutate(part.data_CC,Analysis="Climate Change")
part.data<-rbind(part.data_pub,part.data_CC) %>% 
  arrange(Stage, Percent) %>% 
  mutate(order = row_number())
part.data$order<-c(1,2,3,3,4,4,5,6,7,8,6,9,10,8,9,11,12,10,13,12,13,14,14,15,16,17,18,19,20,
                   16,17,18,20,21,22,23,24,25,21,23,26,25,26,27,27,28,29,30,31,29,32,30,33,
                   32,33,34,35,36,37,38,39,39)
drive.data_pub<-mutate(drive.data_pub,Analysis="Random Sample") %>% 
  mutate(Percent=round(Percent,0)) %>% 
  select(Analysis,Driver,Percent,Frequency)
drive.data_CC<-mutate(drive.data_CC,Analysis="Climate Change")%>% 
  mutate(Percent=round(Percent,0)) %>% 
  select(Analysis,Driver,Percent,Frequency)
drive.data<-rbind(drive.data_pub,drive.data_CC) %>% 
  arrange(Percent) %>%
  mutate(order = row_number())
drive.data$order<-c(6,5,4,3,2,1,8,7,12,9,3,15,14,13,12,11,10,14,16,15,
                   16,6)
# Wrangle objective category data by Random Sample, climate change, and combined
objcat.data_pub<-mutate(objcat.data_pub,Analysis="Random Sample") %>% 
  mutate(Percent=round(Percent,0)) %>% 
  select(Analysis,'Objective Category',Percent,Frequency)
objcat.data_CC<-mutate(objcat.data_CC,Analysis="Climate Change")%>% 
  mutate(Percent=round(Percent,0)) %>% 
  select(Analysis,'Objective Category',Percent,Frequency)
objcat.data<-rbind(objcat.data_pub,objcat.data_CC) %>% 
  rename(OC='Objective Category') %>% 
  arrange(OC) %>% 
  rename('Objective Category'=OC)

# Wrangle objective data by Random Sample, climate change, and combined
obj.dataTable_pub<-mutate(obj.dataTable_pub,Analysis="Random Sample") %>% 
  mutate(Percent=round(Percent,0))
obj.dataTable_CC<-mutate(obj.dataTable_CC,Analysis="Climate Change")%>% 
  mutate(Percent=round(Percent,0))
obj.dataTable<-rbind(obj.dataTable_pub,obj.dataTable_CC) %>% 
  filter(Objective=="Category") %>%
  group_by(Analysis) %>% 
  summarise('AVG'=sum(Number)) %>% 
  mutate(count=c(11,30)) %>% 
  mutate('Per MSE'=round(AVG/count,1)) %>% 
  mutate('Type'=c("Objectives","Objectives"))

altcat.data_pub<-mutate(altcat.data_pub,Analysis="Random Sample") %>% 
  mutate(Percent=round(Percent,0))
altcat.data_CC<-mutate(altcat.data_CC,Analysis="Climate Change")%>% 
  mutate(Percent=round(Percent,0))
altcat.data<-rbind(altcat.data_pub,altcat.data_CC) %>%
  group_by(Analysis) %>% 
  summarise('AVG'=sum(Number)) %>% 
  mutate(count=c(11,30)) %>% 
  mutate('Per MSE'=round(AVG/count,1)) %>% 
  mutate('Type'=c("Alternatives","Alternatives"))

per.MSE<-obj.dataTable %>% 
  mutate(order=c(2,1)) %>% 
  arrange(order) %>% 
  select(Analysis,'Per MSE')

##### Data Analysis Outputs #####
# number of climate change MSE articles
# n_CC

# plot MSEs on map
MSE.map<-ggplot(data=map.data,aes(x=Longitude, y=Latitude,color=Drivers)) + world +
  geom_point(size=2.5) + scale_color_manual(values=c("#66CCCC","#006666")) +  theme_void() +
  theme(legend.position = c(0.15, 0.25))

# plot explicit documentation of steps or components of MSE processes
# Random Sample MSEs
Freq.plot<-ggplot(freq.data_pub,aes(Explicit,Percent))+
  geom_col()+
  coord_flip() +
  scale_y_continuous(limits=c(0,100),expand = c(0,0))+xlab(NULL)+
  scale_x_discrete(
    limits=c("Decision","Tradeoffs",
             "Alternatives","Objectives","Problem","Process"),
    labels=c("Decision","Tradeoffs",
             "Alternatives","Objectives","Problem","Process")) + theme_bw()

Part.plot<-ggplot(part.data_pub,aes(x=order,y=Percent)) +
  facet_wrap(~Stage,scale="free",ncol=2) + geom_col() +
  scale_fill_manual(values=c("#66CCCC","#006666")) +
  scale_x_continuous(breaks = part.data$order,
                     labels = part.data$Participants)+
  scale_y_continuous(limits=c(0,100),expand = c(0,0)) +
  ylab("Percent")+xlab(NULL)+coord_flip() + theme_bw()

Driver.plot<-ggplot(drive.data,aes(x=order,y=Percent,fill=Analysis)) +
  geom_col(position="dodge") +
  scale_fill_manual(values=c("#66CCCC","#006666")) +
  scale_x_continuous(breaks = drive.data$order,
                     labels = drive.data$Driver)+
  scale_y_continuous(limits=c(0,100),expand = c(0,0))+
  ylab("Percent")+xlab(NULL)+coord_flip() +
  guides(fill = guide_legend(reverse=T)) + theme_bw() +
  theme(legend.position = c(0.825,0.075),legend.title = element_blank())
```

# Introduction
Fisheries management has mostly focused on fishing impacts with ecosystem status viewed as a background constant.
  
The increasing rate of climate change is changing this dynamic, bringing ecosystem status to the forefront of fisheries management.

Management strategy evaluation (MSE) is "widely considered to be the most appropriate way to evaluate the trade‐offs achieved by alternative management strategies and to assess the consequences of uncertainty for achieving management goals” [@R-Punt]. Thus, MSE is a compelling tool to assess climate change impacts and test climate-ready options for fisheries management decisions.

Adaptive management arose to address uncertainties and accelerate progress towards meeting management objectives. We used the structured decision making (SDM) process [@R-SDM] -- the decision making framework in which adaptive management occurs -- as our framework, how do published MSE projects utilize standard SDM components and support learning within the MSE practitioner community?  

### Objectives
We review published MSEs against the steps of the SDM framework to:  

* Determine the rate of documentation, and use of steps, in the MSE process:  
* Identify participants in MSE processes.
* Highlight unique aspects of MSEs that model climate change as a driver.
* Identify aspects of successful MSEs that can be adopted to inform fisheries management in a changing climate  
* Provide insights about MSE processes and documentation that can further learning to improve future MSEs

# Methods
## Finding and Sampling the MSE Literature
We conducted our search for MSEs in the SCI-EXPANDED index from Web of Science, searching for “management strategy evaluation” by topic across all years on January 8th, 2019. This search returned 253 results.  We reviewed a random sample of 30 articles that document a MSE, removing articles that were reviews, meta-analyses, or simply cited other MSE articles from our sample. Of the 253 articles, 11 included climate change as a driver of fishery status, and after removing other articles we estimate 110-160 articles document a MSE.   

| MSE type | Count |
|:--:|:--:|
| Published (estimated) | 110-160 |
| Random Sample | 30 |
| Climate Change | 11 |  

## Reviewing MSE documentation 
Methods for scoring the documentation.

# Results
## Are structured decision making steps explicit in MSEs?
The majority of MSEs did not explicitly document how the stages of the MSE process -- defined using the SDM framework -- were completed (Table \@ref(tab:explicit)).  The most documented stage was the alternative stage, while 3 of the 30 studies explicitly documented a tradeoff analysis and 2 of the 30 documented a management decision.

```{r explicit}
freq.data_pub %>%
  mutate("Percent"=round(Percent,0)) %>% 
  kable(align = "c", caption = "Prevalence of Explicit Documentation of stages in the MSE process")
```

### Who is involved in MSEs?
The primary participants and leaders of the MSE processes were scientists, with some lead by governments and management agencies (Figure \@ref(fig:participants)).  Objectives and alternatives were elicited from a variety of participants, with scientists seemingly selecting these components in cases where documentation was inexplicit.

```{r participants, fig.cap='Who guided, participated in, or provided input during the specified steps of the MSE process', fig.height=6, out.width="100%"}
Part.plot
```

<!-- ### Where have climate change MSEs occurred? -->
<!-- To date MSEs modeling climate change have been concentrated in North America and Australia (Figure \@ref(fig:mapfigure)). -->

<!-- ```{r, mapfigure, fig.cap='Map of MSE study locations.', fig.height=4, out.width="100%"} -->
<!-- MSE.map + -->
<!--   theme(text = element_text(size=14)) -->
<!-- ``` -->



<!-- ### What questions and management objectives do MSEs address? -->
<!-- Uncertainty in system parameters was the main driver of the system state, but a variety of drivers were considered across the random sample of MSEs (Figure \@ref(fig:driversPlot)). -->

<!-- ```{r driversPlot, fig.cap='Drivers included in MSE models', fig.height=6, out.width="100%"} -->
<!-- Driver.plot + -->
<!--   theme(text = element_text(size=14)) -->
<!-- ``` -->

<!-- More objectives were considered per MSE in the random sample than in the climate change MSEs (Table \@ref(tab:PerMSE)).  Climate change MSEs were less likely to consider economic and social objectives than the random sample (Table \@ref(tab:objectiveCategories)). -->

<!-- ```{r, PerMSE} -->
<!-- color_Pub <- which(per.MSE$Analysis=='Random Sample') -->
<!-- color_CC <- which(per.MSE$Analysis=='Climate Change') -->

<!-- per.MSE %>% -->
<!--   kable(align = "c", caption = "Number of objectives considered per management strategy evaluation") %>%   -->
<!--   row_spec(color_CC, color = "#66CCCC", background = "white") %>% -->
<!--   row_spec(color_Pub, color = "#006666", background = "white") -->
<!-- ``` -->

<!-- ```{r, objectiveCategories} -->
<!-- color_Pub <- which(objcat.data$Analysis=='Random Sample') -->
<!-- color_CC <- which(objcat.data$Analysis=='Climate Change') -->

<!-- objcat.data %>% -->
<!--   kable(align = "c", caption = "Objective categories considered in management strategy evaluations") %>% -->
<!--   row_spec(color_CC, color = "#66CCCC", background = "white") %>% -->
<!--   row_spec(color_Pub, color = "#006666", background = "white") -->
<!-- ``` -->

### Main Conclusions
The picture painted by MSE documentation is one of scientist driven simulation studies rather than management driven decision processes. 
While documentation about the **modeling** conducted in a MSE was explicit, documentation about the **process used to make decisions** about the MSE model **were limited**. Scientists participated in, or seemingly directly selected the objectives and alternatives to evaluate in most MSEs. Facilitators and decision analysts -- participants focused on the decision making process -- were rarely participants in MSE processes.  Conservation, Economic, and Yield focused objectives were commonly considered, while **broader social objectives were rarely considered**.

Despite numerous applications of MSE, the applications that include climate change are limited, leaving uncertainty about the best approach to MSE use for fishereis management that accounts for a changing environment.

### Explore our review on the web!
Check out our shiny app (<https://jonathancummings.shinyapps.io/MSEreview/>).

### References

# Discussion

Academic workflow, certainly in political science, is at a crossroads. The *American Journal of Political Science* (*AJPS*) announced a (my words) ["show your work" initiative](http://ajps.org/2015/03/26/the-ajps-replication-policy-innovations-and-revisions/) in which authors who are tentatively accepted for publication at the journal must hand over the raw code and data that produced the results shown in the manuscript. The editorial team at *AJPS* then reproduces the code from the manuscript. Pending successful replication, the manuscript moves toward publication. The *AJPS* might be at the fore of this movement, and it could be the most aggressive among political science journals, but other journals in our field have signed the joint [Data Access & Research Transparency](http://www.dartstatement.org/) (DART) initiative. This, at a bare minimum, requires uploading code from quantitatively-oriented published articles to in-house directories hosted by the journal or to services like [Dataverse](http://dataverse.org/). 

There are workflow implications to the Lacour controversy as well. Political science, for the foreseeable future, will struggle with the extent of [the data fraud perpetrated by Michael Lacour](http://stanford.edu/~dbroock/broockman_kalla_aronow_lg_irregularities.pdf) in an article co-authored with Donald P. Green in *Science*, the general scientific journal of record in the United States. A failure to reproduce LaCour's results with different samples uncovered a comprehensive effort by LaCour to "fake" data that provided results to what we felt or believed to be true [(i.e. "truthiness")](http://chronicle.com/article/LAffaire-LaCour/230905/). However, [fake data can have real consequences](http://kieranhealy.org/blog/archives/2015/05/20/fake-science-real-consequences/) for both the researcher and those who want to learn from it and use it for various purposes. Even research done honestly may suffer the same fate if researchers are not diligent in their workflow.

These recent events underscore the DART push and cast a shadow over our workflow. However, good workflow has always been an issue in our discipline. Cloud storage services like [Dropbox](http://www.dropbox.com) are still relatively new among political scientists. Without cloud storage, previous workflow left open the possibility that work between a home computer and an office computer was lost as a function of a corrupted thumb drive, an overheated power supply, or, among other things, the wave of viruses that [would particularly affect Microsoft users every summer](http://money.cnn.com/2003/11/05/technology/microsoftbounty/). Social sciences, [unlike engineering](http://kieranhealy.org/blog/archives/2014/01/23/plain-text/), have traditionally relied on software like Microsoft Word for manuscript preparation though any word processor reduces workflow to a series of clicks and strokes on a keyboard. This is [a terrible way to track changes](http://www.nytimes.com/2013/04/19/opinion/krugman-the-excel-depression.html) or maintain version control. The addition of collaborators only compounds all the aforementioned issues. The proverbial left hand may not know what the right hand is doing.

I think there is reason for optimism. We only struggle with it now because we have tools like [R Markdown](http://rmarkdown.rstudio.com/) and [Pandoc](http://pandoc.org/), more generally, that make significant strides in workflow. LaTeX resolved earlier issues of corrupted binary files by reducing documents to raw markup that was little more than raw text and revisions that could be easily kept as ["commented" text](http://tex.stackexchange.com/questions/11177/how-to-write-hidden-notes-in-a-latex-file). However, for all its benefits (including pretty PDFs), [LaTeX is *ugly* code](http://www-rohan.sdsu.edu/~aty/bibliog/latex/gripe.html) and does not provide means of seamlessly working with the actual data analysis itself. R Markdown both eliminates markup and allows the author and her collaborators to write and reproduce the manuscript in one fell swoop.

# Getting Started with YAML

The lion's share of a R Markdown document will be raw text, though the front matter may be the most important part of the document. R Markdown uses [YAML](http://www.yaml.org/) for its metadata and the fields differ from [what an author would use for a Beamer presentation](http://svmiller.com/blog/2015/02/moving-from-beamer-to-r-markdown/). I provide a sample YAML metadata largely taken from this exact document and explain it below.

```{r eval=FALSE}
---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: ~/Dropbox/miscelanea/svm-r-markdown-templates/svm-latex-ms.tex
title: "A Pandoc Markdown Article Starter and Template"
thanks: "Replication files are available on the author's Github account..."
author:
- name: Steven V. Miller
  affiliation: Clemson University
- name: Mary Margaret Albright
  affiliation: Pendelton State University
- name: Rembrandt Q. Einstein
  affiliation: Springfield University
abstract: "This document provides an introduction to R Markdown, argues for its..."
keywords: "pandoc, r markdown, knitr"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
bibliography: "`r paste0(Sys.getenv('HOME'),'/Dropbox/master.bib')`"
biblio-style: apsr
---
```

`output:` will tell R Markdown we want a PDF document rendered with LaTeX. Since we are adding a fair bit of custom options to this call, we specify `pdf_document:` on the next line (with, importantly, a two-space indent). We specify additional output-level options underneath it, each are indented with four spaces. `citation_package: natbib` tells R Markdown to use `natbib` to handle bibliographic citations.[^natbib] Thereafter, the next line (`keep_tex: true`) tells R Markdown to render a raw `.tex` file along with the PDF document. This is useful for both debugging and the publication stage, when the editorial team will ask for the raw `.tex` so that they could render it and later provide page proofs. The next line `fig_caption: true` tells R Markdown to make sure that whatever images are included in the document are treated as figures in which our caption in brackets in a Markdown call is treated as the caption in the figure. The next line (`latex_engine: pdflatex`) tells R Markdown to use pdflatex and not some other option like `lualatex`. For my template, I'm pretty sure this is mandatory.[^pdflatex]

[^natbib]: R Markdown can use Pandoc's native bibliography management system or even `biblatex`, but I've found that it chokes with some of the more advanced stuff I've done with my .bib file over the years. For example, I've been diligent about special characters (e.g. umlauts and acute accents) in author names in my .bib file, but Pandoc's native citation system will choke on these characters in a .bib file. I effectively need `natbib` for my own projects.
[^pdflatex]: The main reason I still use `pdflatex` (and most readers probably do as well) is because of LaTeX fonts. [Unlike others](http://www-rohan.sdsu.edu/~aty/bibliog/latex/gripe.html), I find standard LaTeX fonts to be appealing.

The next line (`template: ...`) tells R Markdown to use my custom LaTeX template.[^path] While I will own any errors in the code, I confess to "Frankensteining" this template from [the default LaTeX template](https://github.com/jgm/pandoc-templates) from Pandoc, [Kieran Healy's LaTeX template](https://github.com/kjhealy/pandoc-templates/tree/master/templates), and liberally using raw TeX from the [Association for Computing Machinery's (ACM) LaTeX template](https://www.acm.org/publications/article-templates/acm-latex-style-guide). I rather like that template since it resembles standard manuscripts when they are published in some of our more prominent journals. I will continue with a description of the YAML metadata in the next paragraph, though invite the curious reader to scroll to the end of the accompanying post to see the PDF this template produces.


[^path]: Notice that the path is relative. The user can, if she wishes, install this in the default Pandoc directory. I don't think this is necessary. Just be mindful of wherever the template is placed. Importantly, `~` is used in R to find the home directory (not necessarily the working directory). It is equivalent to saying `/home/steve` in Linux, or `/Users/steve` on a Mac, in my case.

The next fields get to the heart of the document itself. `title:` is, intuitively, the title of the manuscript. Do note that fields like `title:` do not have to be in quotation marks, but must be in quotation marks if the title of the document includes a colon. That said, the only reason to use a colon in an article title is if it is followed by a subtitle, hence the optional field (`subtitle:`). Notice I "comment out" the subtitle in the above example with a pound sign since this particular document does not have a subtitle. If `thanks:` is included and has an accompanying entry, the ensuing title of the document gets an asterisk and a footnote. This field is typically used to advise readers that the document is a working paper or is forthcoming in a journal.

The next field (`author:`) is a divergence from standard YAML, but I think it is useful. I will also confess to pilfering this idea from Kieran Healy's template. Typically, multiple authors for a given document are separated by an `\and` in this field. However, standard LaTeX then creates a tabular field separating multiple authors that is somewhat restrictive and not easy to override. As a result, I use this setup (again, taken from Kieran Healy) to sidestep the restrictive rendering of authors in the standard `\maketitle` tag. After `author:`, enter `- name:` (no space before the dash) and fill in the field with the first author. On the next line, enter two spaces, followed by `affiliation:` and the institute or university affiliation of the first author.

Do notice this can be repeated for however many co-authors there are to a manuscript. The rendered PDF will enter each co-author in a new line in a manner similar to journals like *American Journal of Political Science*, *American Political Science Review*, or *Journal of Politics*.

The next two fields pertain to the frontmatter of a manuscript. They should also be intuitive for the reader. `abstract` should contain the abstract and `keywords` should contain some keywords that describe the research project. Both fields are optional, though are practically mandatory. Every manuscript requires an abstract and some journals---especially those published by Sage---request them with submitted manuscripts. My template also includes these keywords in the PDF's metadata.

`date` comes standard with R Markdown and you can use it to enter the date of the most recent compile. I typically include the date of the last compile for a working paper in the `thanks:` field, so this field currently does not do anything in my Markdown-LaTeX manuscript template. I include it in my YAML as a legacy, basically.

The next items are optional and cosmetic. `geometry:` is a standard option in LaTeX. I set the margins at one inch, and you probably should too. `fontfamily:` is optional, but I use it to specify the Palatino font. The default option is Computer Modern Roman. `fontsize:` sets, intuitively, the font size. The default is 10-point, but I prefer 11-point. `spacing:` is an optional field. If it is set as "double", the ensuing document is double-spaced. "single" is the only other valid entry for this field, though not including the entry in the YAML metadata amounts to singlespacing the document by default. Notice I have this "commented out" in the example code.

The final two options pertain to the bibliography. `bibliography:` specifies the location of the .bib file, so the author could make citations in the manuscript. `biblio-style` specifies the type of bibliography to use. You'll typically set this as APSR. You could also specify the relative path of [my *Journal of Peace Research* .bst file](http://svmiller.com/miscellany/journal-of-peace-research-bst-file/) if you are submitting to that journal.

# Getting Started with Markdown Syntax

There are a lot of cheatsheets and reference guides for Markdown (e.g. [Adam Prichard](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet), [Assemble](http://assemble.io/docs/Cheatsheet-Markdown.html), [Rstudio](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf), [Rstudio again](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf), [Scott Boms](http://scottboms.com/downloads/documentation/markdown_cheatsheet.pdf), [Daring Fireball](https://daringfireball.net/projects/markdown/syntax), among, I'm sure, several others). I encourage the reader to look at those, though I will retread these references here with a minimal working example below.

```markdown

# Introduction

**Lorem ipsum** dolor *sit amet*. 

- Single asterisks italicize text *like this*. 
- Double asterisks embolden text **like this**.

Start a new paragraph with a blank line separating paragraphs.

- This will start an unordered list environment, and this will be the first item.
- This will be a second item.
- A third item.
    - Four spaces and a dash create a sublist and this item in it.
- The fourth item.
    
1. This starts a numerical list.
2. This is no. 2 in the numerical list.
    
# This Starts A New Section
## This is a Subsection
### This is a Subsubsection
#### This starts a Paragraph Block.

> This will create a block quote, if you want one.
Want a table? This will create one.

Table Header  | Second Header
------------- | -------------
Table Cell    | Cell 2
Cell 3        | Cell 4 

Note that the separators *do not* have to be aligned.

Want an image? This will do it.

![caption for my image](path/to/image.jpg)

`fig_caption: yes` will provide a caption. Put that in the YAML metadata.

Almost forgot about creating a footnote.[^1] This will do it again.[^2]

[^1]: The first footnote
[^2]: The second footnote

Want to cite something? 

- Find your biblatexkey in your bib file.
- Put an @ before it, like @smith1984, or whatever it is.
- @smith1984 creates an in-text citation (e.g. Smith (1984) says...)
- [@smith1984] creates a parenthetical citation (Smith, 1984)

That'll also automatically create a reference list at the end of the document.

[In-text link to Google](http://google.com) as well.
```

That's honestly it. Markdown takes the chore of markup from your manuscript (hence: "Markdown").

On that note, you could easily pass most LaTeX code through Markdown if you're writing a LaTeX document. However, you don't need to do this (unless you're using the math environment) and probably shouldn't anyway if you intend to share your document in HTML as well.

# Using R Markdown with Knitr

Perhaps the greatest intrigue of R Markdown comes with the [`knitr` package](http://yihui.name/knitr/) provided by @xie2013ddrk. In other words, the author can, if she chooses, do the analysis in the Markdown document itself and compile/execute it in R.

Take, for example, this simple exercise using the `voteincome` data from the `Zelig` package. Suppose I want to explain the decision to vote using data from this package. I load in the data, clean the data, run the analyses, and present the results as a coefficient plot.

Here's what this code looks like. All I did was create a code display, which starts with three *backticks* (i.e. those ticks next to the number 1 key on your keyboard) and ends with three backticks on another line. On the first line of backticks (i.e. to start the code display) enter `{r, eval=FALSE, tidy=TRUE}`. The `eval=FALSE` option just displays the R code (and does not run it), `tidy=TRUE` wraps long code so it does not run off the page.

Within that code display, I enter my R code like this.


```{r, eval=FALSE, tidy = TRUE}
library(stevemisc)
data(uniondensity)
M1 <- lm(union ~ left + size + concen, data=uniondensity)
library(arm)
coefplot(M1)
```

The implications for workflow are faily substantial. Authors can rather quickly display the code they used to run the analyses in the document itself (likely in the appendix). As such, there's little guesswork for reviewers and editors in understanding what the author did in the analyses reported in the manuscript.

It doesn't end there. In fact, here's what happens when `eval=FALSE` is omitted or changed to `eval=TRUE`. Now, the code runs within R. Observe.

```{r, eval=TRUE, tidy = TRUE, cache=FALSE, fig.cap="A Coefficient Plot", message=F, warning=F}
library(stevemisc)
data(uniondensity)
M1 <- lm(union ~ left + size + concen, data=uniondensity)
library(arm)
coefplot(M1)
```

To get `knitr` to present the results of a table, add `results="asis"` to the brackets to start the R code chunk. The ensuing output will look like this (though the table may come on the next page).

```{r, eval=TRUE, tidy = TRUE, size="small", cache=FALSE, results="asis", message=F, warning=F}
library(stevemisc)
data(uniondensity)
library(stargazer)
M1 <- lm(union ~ left + size + concen, data=uniondensity)
stargazer(M1, title="A Handsome Table", header=FALSE)
```

Adding `echo="FALSE"` inside the brackets to start the R chunk will omit the presentation of the R commands. It will just present the table. This provides substantial opportunity for authors in doing their analyses. Now, the analysis and presentation in the form of a polished manuscript can be effectively simultaneous.[^4]

[^4]: I'm not sure if I'm ready to commit to this myself since my workflow is still largely derived from [Rob J. Hyndman's example](http://robjhyndman.com/hyndsight/workflow-in-r/). However, *knitr* has endless potential, especially when analyses can stored in cache, saved as chunks, or loaded in the preamble of a document to reference later in the manuscript.


<!--
# References
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\vspace*{-0.2in}
\noindent
-->